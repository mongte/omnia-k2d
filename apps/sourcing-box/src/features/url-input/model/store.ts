import { create } from 'zustand'
import { devtools } from 'zustand/middleware'
import { Product, CrawlStatus, CrawlRequest } from '@entities/product'

// URL ì •ê·œí™” ë° ì¤‘ë³µ ì œê±° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
const normalizeAndDeduplicateUrls = (urls: string[]): string[] => {
  // shop ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
  const extractShopName = (url: string): string | null => {
    try {
      const urlObj = new URL(url)
      const pathname = urlObj.pathname
      
      // /shop/shopname íŒ¨í„´ì—ì„œ shopname ì¶”ì¶œ
      const shopMatch = pathname.match(/\/shop\/([^/]+)/)
      if (shopMatch) {
        return shopMatch[1]
      }
      
      // /g/shopname íŒ¨í„´ë„ ì§€ì› (ì¼ë¶€ qoo10 URLì—ì„œ ì‚¬ìš©)
      const gMatch = pathname.match(/\/g\/([^/]+)/)
      if (gMatch) {
        return gMatch[1]
      }
      
      return null
    } catch (error) {
      console.warn('URL íŒŒì‹± ì‹¤íŒ¨:', url, error)
      return null
    }
  }

  // URL ì •ê·œí™” (www.qoo10.jp -> m.qoo10.jp ìš°ì„ )
  const normalizeUrl = (url: string): string => {
    try {
      const urlObj = new URL(url)
      
      // ë°ìŠ¤í¬í†± ë„ë©”ì¸ì„ ëª¨ë°”ì¼ ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½
      if (urlObj.hostname.startsWith('www.')) {
        urlObj.hostname = urlObj.hostname.replace('www.', 'm.')
      }
      
      return urlObj.toString()
    } catch (error) {
      console.warn('URL ì •ê·œí™” ì‹¤íŒ¨:', url, error)
      return url
    }
  }

  console.log('ğŸ”§ normalizeAndDeduplicateUrls - ì…ë ¥ URLs:', JSON.stringify(urls))

  // ë¨¼ì € ëª¨ë“  URLì„ ë””ì½”ë”©í•˜ê³  ì •ë¦¬
  const cleanedUrls = urls.map(url => {
    let cleanUrl = url.trim()
    try {
      // URL ë””ì½”ë”© (%20 ê°™ì€ ì¸ì½”ë”©ëœ ë¬¸ì ì²˜ë¦¬)
      cleanUrl = decodeURIComponent(cleanUrl)
      cleanUrl = cleanUrl.trim() // ë””ì½”ë”© í›„ ë‹¤ì‹œ trim
    } catch (error) {
      console.warn('URL ë””ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©:', cleanUrl, error)
    }
    return cleanUrl
  }).filter(url => url.length > 0)

  console.log('ğŸ”§ ì •ë¦¬ëœ URLs:', JSON.stringify(cleanedUrls))

  // shop ì´ë¦„ë³„ë¡œ URL ê·¸ë£¹í™”
  const shopGroups = new Map<string, string[]>()
  const urlsWithoutShop: string[] = []

  cleanedUrls.forEach(url => {
    const shopName = extractShopName(url)
    
    if (shopName) {
      if (!shopGroups.has(shopName)) {
        shopGroups.set(shopName, [])
      }
      const group = shopGroups.get(shopName)
      if (group) {
        group.push(url)
      }
    } else {
      // shopì´ ê°ì§€ë˜ì§€ ì•Šì€ URLì€ ê·¸ëŒ€ë¡œ ìœ ì§€
      urlsWithoutShop.push(url)
    }
  })

  console.log('ğŸ”§ Shop ê·¸ë£¹í™” ê²°ê³¼:', Object.fromEntries(shopGroups))
  console.log('ğŸ”§ Shopì´ ì—†ëŠ” URLs:', urlsWithoutShop)

  // ê° shop ê·¸ë£¹ì—ì„œ í•˜ë‚˜ì˜ URLë§Œ ì„ íƒ (ëª¨ë°”ì¼ ë²„ì „ ìš°ì„ )
  const deduplicatedUrls: string[] = []

  shopGroups.forEach((groupUrls, shopName) => {
    // ëª¨ë°”ì¼ ë²„ì „ì´ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
    const mobileUrl = groupUrls.find(url => url.includes('m.qoo10'))
    
    if (mobileUrl) {
      deduplicatedUrls.push(normalizeUrl(mobileUrl))
      console.log(`ğŸ”§ Shop "${shopName}": ëª¨ë°”ì¼ ë²„ì „ ì„ íƒ - ${mobileUrl}`)
    } else {
      // ëª¨ë°”ì¼ ë²„ì „ì´ ì—†ìœ¼ë©´ ë°ìŠ¤í¬í†± ë²„ì „ì„ ì •ê·œí™”í•´ì„œ ì¶”ê°€
      const firstUrl = groupUrls[0]
      const normalized = normalizeUrl(firstUrl)
      deduplicatedUrls.push(normalized)
      console.log(`ğŸ”§ Shop "${shopName}": ë°ìŠ¤í¬í†± ë²„ì „ ì •ê·œí™” - ${firstUrl} -> ${normalized}`)
    }
  })

  // shopì´ ê°ì§€ë˜ì§€ ì•Šì€ URLë“¤ë„ ì •ê·œí™”í•´ì„œ ì¶”ê°€ (www -> m)
  urlsWithoutShop.forEach(url => {
    const normalized = normalizeUrl(url)
    deduplicatedUrls.push(normalized)
    console.log(`ğŸ”§ Shop ë¯¸ê°ì§€ URL ì •ê·œí™” (www->m): ${url} -> ${normalized}`)
  })

  // ìµœì¢… ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ë™ì¼í•œ URLì´ ìƒì„±ëœ ê²½ìš°)
  const uniqueUrls = Array.from(new Set(deduplicatedUrls))
  
  console.log('ğŸ”§ normalizeAndDeduplicateUrls - ìµœì¢… ê²°ê³¼:', JSON.stringify(uniqueUrls))
  return uniqueUrls
}

interface UrlInputState {
  urls: string[]
  isValidating: boolean
  errors: Record<number, string>
  productsPerUrl: number // ê° URLë‹¹ ì¶”ì¶œí•  ìƒí’ˆ ê°œìˆ˜
  
  // Textarea ë°©ì‹ì„ ìœ„í•œ ìƒíƒœ
  inputMode: 'individual' | 'bulk' // ì…ë ¥ ëª¨ë“œ
  bulkUrls: string // textarea ë‚´ìš©
  bulkErrors: string[] // bulk ëª¨ë“œ ì—ëŸ¬ë“¤
  
  // í¬ë¡¤ë§ ìƒíƒœ
  crawlStatus: CrawlStatus
  crawledProducts: Product[]
  crawlErrors: string[]
  crawlLogs: string[]
  
  // Actions
  addUrl: () => void
  removeUrl: (index: number) => void
  updateUrl: (index: number, url: string) => void
  setUrls: (urls: string[]) => void
  validateUrl: (index: number, url: string) => void
  clearAll: () => void
  getValidUrls: () => string[]
  setProductsPerUrl: (count: number) => void
  getCrawlRequest: () => CrawlRequest
  
  // Bulk mode actions
  setInputMode: (mode: 'individual' | 'bulk') => void
  setBulkUrls: (urls: string) => void
  validateBulkUrls: () => void
  parseBulkUrls: () => string[]
  
  // í¬ë¡¤ë§ Actions
  setCrawlStatus: (status: Partial<CrawlStatus>) => void
  setCrawledProducts: (products: Product[]) => void
  addCrawlError: (error: string) => void
  addCrawlLog: (log: string) => void
  clearCrawlData: () => void
  resetCrawlStatus: () => void
}

export const useUrlInputStore = create<UrlInputState>()(
  devtools(
    (set, get) => ({
      urls: [''],
      isValidating: false,
      errors: {},
      productsPerUrl: 5, // ê¸°ë³¸ê°’ì„ 5ë¡œ ë³€ê²½
      
      // Textarea ë°©ì‹ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°ê°’
      inputMode: 'individual',
      bulkUrls: '',
      bulkErrors: [],

      // í¬ë¡¤ë§ ìƒíƒœ ì´ˆê¸°ê°’
      crawlStatus: {
        isRunning: false,
        progress: 0,
        currentUrl: '',
        completedUrls: 0,
        totalUrls: 0,
      },
      crawledProducts: [],
      crawlErrors: [],
      crawlLogs: [],

      addUrl: () => {
        set((state) => ({
          urls: [...state.urls, '']
        }))
      },

      removeUrl: (index: number) => {
        set((state) => ({
          urls: state.urls.filter((_, i) => i !== index),
          errors: Object.keys(state.errors).reduce((acc, key) => {
            const keyNum = parseInt(key)
            if (keyNum < index) {
              acc[keyNum] = state.errors[keyNum]
            } else if (keyNum > index) {
              acc[keyNum - 1] = state.errors[keyNum]
            }
            return acc
          }, {} as Record<number, string>)
        }))
      },

      updateUrl: (index: number, url: string) => {
        set((state) => {
          // URL ë””ì½”ë”© ì²˜ë¦¬
          let cleanUrl = url.trim()
          try {
            cleanUrl = decodeURIComponent(cleanUrl)
            cleanUrl = cleanUrl.trim()
          } catch (error) {
            // ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
            console.warn('URL ë””ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©:', cleanUrl, error)
          }
          
          const newUrls = [...state.urls]
          newUrls[index] = cleanUrl
          
          // Clear error for this index when user starts typing
          const newErrors = { ...state.errors }
          if (newErrors[index]) {
            delete newErrors[index]
          }
          
          return {
            urls: newUrls,
            errors: newErrors
          }
        })
      },

      setUrls: (urls: string[]) => {
        set({
          urls: urls,
          errors: {}
        })
      },

      validateUrl: (index: number, url: string) => {
        // URL ë””ì½”ë”© ì²˜ë¦¬
        let cleanUrl = url.trim()
        try {
          cleanUrl = decodeURIComponent(cleanUrl)
          cleanUrl = cleanUrl.trim()
        } catch (error) {
          console.warn('Validation ì¤‘ URL ë””ì½”ë”© ì‹¤íŒ¨:', cleanUrl, error)
        }
        
        const urlPattern = /^https?:\/\/.+/
        const qoo10Pattern = /qoo10\.(jp|co\.kr|sg)/
        
        let error = ''
        
        if (!cleanUrl) {
          error = 'URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”'
        } else if (!urlPattern.test(cleanUrl)) {
          error = 'ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤'
        } else if (!qoo10Pattern.test(cleanUrl)) {
          error = 'Qoo10 ì‚¬ì´íŠ¸ URLë§Œ ì§€ì›í•©ë‹ˆë‹¤'
        }
        
        set((state) => ({
          errors: error 
            ? { ...state.errors, [index]: error }
            : Object.keys(state.errors).reduce((acc, key) => {
                if (parseInt(key) !== index) {
                  acc[parseInt(key)] = state.errors[parseInt(key)]
                }
                return acc
              }, {} as Record<number, string>)
        }))
      },

      clearAll: () => {
        set({
          urls: [''],
          errors: {}
        })
      },

      getValidUrls: () => {
        const { urls, errors } = get()
        return urls.filter((url, index) => 
          url.trim() && !errors[index]
        )
      },

      setProductsPerUrl: (count: number) => {
        set({ productsPerUrl: count })
      },

      getCrawlRequest: () => {
        const { inputMode, productsPerUrl, getValidUrls, parseBulkUrls } = get()
        console.log('ğŸš€ getCrawlRequest - inputMode:', inputMode)
        
        let urls: string[] = []
        
        if (inputMode === 'individual') {
          const rawUrls = getValidUrls()
          console.log('ğŸš€ getCrawlRequest - rawUrls from individual:', JSON.stringify(rawUrls))
          
          // ë¨¼ì € ì½¤ë§ˆ ë¶„ë¦¬ ì²˜ë¦¬
          const expandedUrls: string[] = []
          rawUrls.forEach(url => {
            if (url.includes(',')) {
              // ì½¤ë§ˆê°€ í¬í•¨ëœ ê²½ìš° ë¶„ë¦¬í•˜ê³  ë””ì½”ë”©
              const splitUrls = url.split(',').map(u => {
                let cleanU = u.trim()
                try {
                  cleanU = decodeURIComponent(cleanU)
                  cleanU = cleanU.trim()
                } catch (error) {
                  console.warn('ê°œë³„ ëª¨ë“œì—ì„œ URL ë””ì½”ë”© ì‹¤íŒ¨:', cleanU, error)
                }
                return cleanU
              }).filter(u => u.length > 0)
              expandedUrls.push(...splitUrls)
            } else {
              // ë‹¨ì¼ URLë„ ë””ì½”ë”© ì²˜ë¦¬
              let cleanUrl = url.trim()
              try {
                cleanUrl = decodeURIComponent(cleanUrl)
                cleanUrl = cleanUrl.trim()
              } catch (error) {
                console.warn('ê°œë³„ ëª¨ë“œì—ì„œ ë‹¨ì¼ URL ë””ì½”ë”© ì‹¤íŒ¨:', cleanUrl, error)
              }
              expandedUrls.push(cleanUrl)
            }
          })
          
          console.log('ğŸš€ getCrawlRequest - expandedUrls:', JSON.stringify(expandedUrls))
          
          // ê·¸ ë‹¤ìŒì— ì •ê·œí™” ë° ì¤‘ë³µ ì œê±°
          urls = normalizeAndDeduplicateUrls(expandedUrls)
        } else {
          // ì¼ê´„ ì…ë ¥ ëª¨ë“œì—ì„œëŠ” parseBulkUrlsì—ì„œ ì´ë¯¸ ì •ê·œí™”ë¨
          urls = parseBulkUrls()
        }
        
        console.log('ğŸš€ getCrawlRequest - ìµœì¢… URLs:', JSON.stringify(urls))
        
        const request = {
          urls: urls,
          productsPerUrl: productsPerUrl
        }
        console.log('ğŸš€ getCrawlRequest - ìµœì¢… request:', JSON.stringify(request))
        
        return request
      },

      // Bulk mode actions
      setInputMode: (mode: 'individual' | 'bulk') => {
        set({ inputMode: mode })
      },
      setBulkUrls: (urls: string) => {
        // ì…ë ¥ëœ ì „ì²´ í…ìŠ¤íŠ¸ì— ëŒ€í•´ URL ë””ì½”ë”© ì‹œë„
        let cleanUrls = urls
        try {
          cleanUrls = decodeURIComponent(urls)
        } catch (error) {
          // ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
          console.warn('Bulk URLs ë””ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©:', error)
        }
        
        set({ bulkUrls: cleanUrls, bulkErrors: [] }) // ì…ë ¥ ì‹œ ì—ëŸ¬ ì´ˆê¸°í™”
      },
      validateBulkUrls: () => {
        const { bulkUrls } = get()
        const urls = bulkUrls.split(',').map(url => {
          let cleanUrl = url.trim()
          try {
            // URL ë””ì½”ë”©
            cleanUrl = decodeURIComponent(cleanUrl)
            cleanUrl = cleanUrl.trim()
          } catch (error) {
            console.warn('Validation ì¤‘ URL ë””ì½”ë”© ì‹¤íŒ¨:', cleanUrl, error)
          }
          return cleanUrl
        }).filter(url => url)
        const errors: string[] = []
        
        if (urls.length === 0) {
          errors.push('ìµœì†Œ í•˜ë‚˜ì˜ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”')
        } else {
          urls.forEach((url, index) => {
            if (!/^https?:\/\/.+/.test(url)) {
              errors.push(`URL ${index + 1}: "${url}" - ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤`)
            } else if (!/qoo10\.(jp|co\.kr|sg)/.test(url)) {
              errors.push(`URL ${index + 1}: "${url}" - Qoo10 ì‚¬ì´íŠ¸ URLë§Œ ì§€ì›í•©ë‹ˆë‹¤`)
            }
          })
        }
        
        set({ bulkErrors: errors })
      },
      parseBulkUrls: () => {
        const { bulkUrls } = get()
        console.log('ğŸ” parseBulkUrls - ì›ë³¸ bulkUrls:', JSON.stringify(bulkUrls))
        
        if (!bulkUrls || !bulkUrls.trim()) {
          console.log('ğŸ” parseBulkUrls - ë¹ˆ ë¬¸ìì—´ì´ë¯€ë¡œ ë¹ˆ ë°°ì—´ ë°˜í™˜')
          return []
        }
        
        // ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ê³  ê° URLì„ ì •ë¦¬ (URL ë””ì½”ë”© í¬í•¨)
        const urls = bulkUrls
          .split(',')
          .map(url => {
            let cleanUrl = url.trim()
            try {
              // URL ë””ì½”ë”© (%20 ê°™ì€ ì¸ì½”ë”©ëœ ë¬¸ì ì²˜ë¦¬)
              cleanUrl = decodeURIComponent(cleanUrl)
              cleanUrl = cleanUrl.trim() // ë””ì½”ë”© í›„ ë‹¤ì‹œ trim
            } catch (error) {
              console.warn('URL ë””ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©:', cleanUrl, error)
            }
            return cleanUrl
          })
          .filter(url => url.length > 0)
        
        console.log('ğŸ” parseBulkUrls - ë¶„ë¦¬ëœ URLs:', JSON.stringify(urls))
        
        // URL ì •ê·œí™” ë° ì¤‘ë³µ ì œê±°
        const normalizedUrls = normalizeAndDeduplicateUrls(urls)
        console.log('ğŸ” parseBulkUrls - ì •ê·œí™”ëœ URLs:', JSON.stringify(normalizedUrls))
        
        return normalizedUrls
      },

      // í¬ë¡¤ë§ Actions
      setCrawlStatus: (status: Partial<CrawlStatus>) => {
        set((state) => ({
          crawlStatus: { ...state.crawlStatus, ...status }
        }))
      },

      setCrawledProducts: (products: Product[]) => {
        set({ crawledProducts: products })
      },

      addCrawlError: (error: string) => {
        set((state) => ({
          crawlErrors: [...state.crawlErrors, error]
        }))
      },

      addCrawlLog: (log: string) => {
        set((state) => ({
          crawlLogs: [...state.crawlLogs, `${new Date().toLocaleTimeString()} - ${log}`]
        }))
      },

      clearCrawlData: () => {
        set({
          crawledProducts: [],
          crawlErrors: [],
          crawlLogs: []
        })
      },

      resetCrawlStatus: () => {
        set({
          crawlStatus: {
            isRunning: false,
            progress: 0,
            currentUrl: '',
            completedUrls: 0,
            totalUrls: 0,
          }
        })
      }
    }),
    { name: 'url-input-store' }
  )
) 